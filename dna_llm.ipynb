{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO7JjpO6iDLY7jKeXQfKQ8O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Valasik0/dna-sequence-llm/blob/first-prototype-test/dna_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IispHeKQBkgf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import random\n",
        "import gzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLtDT8SLB00_",
        "outputId": "c6a05d65-dcc6-46b2-8839-6193ebac5597"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleDNATransformer(nn.Module):\n",
        "    def __init__(self, vocab_size=4,\n",
        "                 max_len=256, #context window\n",
        "                 d_model=128, #embedding dim\n",
        "                 n_heads=4,\n",
        "                 n_layers=4): #skryte vrstvy\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, max_len, d_model))\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_heads, batch_first=True)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "        self.head = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.shape[1]\n",
        "        x = self.embed(x) + self.pos_embed[:, :seq_len]\n",
        "        x = self.encoder(x)\n",
        "        logits = self.head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "8ytOnta7Uq0o"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleDNATransformer()\n",
        "x = torch.randint(0, 4, (32, 256))  # batch 32 sekvencí, delka 256 nt\n",
        "logits = model(x)\n",
        "logits.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F5HifHwebgl",
        "outputId": "905b1071-9d20-4c3d-ceed-2b94a08fd7c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 256, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXKGQbin5lTC",
        "outputId": "59b3b72c-9843-4555-bd38-c78e52a796c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 2, 3, 3, 0, 3, 2, 2, 1, 2, 3, 1, 0, 0, 2, 0, 2, 0, 1, 3, 1, 0, 2,\n",
              "        3, 2, 1, 2, 0, 1, 1, 3, 3, 2, 0, 3, 3, 3, 1, 3, 2, 2, 1, 3, 0, 0, 3, 2,\n",
              "        1, 3, 3, 0, 2, 2, 2, 1, 1, 2, 0, 2, 0, 2, 1, 3, 1, 2, 2, 2, 2, 1, 0, 0,\n",
              "        1, 3, 0, 1, 1, 1, 2, 2, 2, 2, 1, 0, 3, 3, 3, 1, 3, 2, 0, 3, 0, 2, 3, 3,\n",
              "        2, 0, 1, 0, 1, 1, 3, 0, 0, 0, 1, 3, 2, 2, 1, 3, 2, 3, 0, 0, 1, 2, 3, 1,\n",
              "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 2, 1, 1, 3, 1, 2, 2, 2, 0, 3, 1, 2, 0, 0,\n",
              "        3, 0, 0, 2, 0, 2, 0, 2, 2, 1, 0, 3, 0, 2, 3, 0, 2, 0, 2, 1, 3, 1, 3, 1,\n",
              "        0, 3, 3, 1, 0, 2, 3, 3, 2, 2, 3, 3, 3, 1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 3,\n",
              "        0, 0, 3, 0, 1, 2, 0, 1, 2, 2, 1, 1, 3, 3, 1, 2, 0, 2, 3, 3, 1, 2, 0, 0,\n",
              "        3, 0, 1, 0, 2, 3, 0, 0, 0, 0, 2, 1, 1, 2, 2, 2, 0, 0, 1, 1, 3, 1, 0, 2,\n",
              "        0, 0, 3, 3, 3, 2, 2, 0, 1, 1, 3, 3, 0, 0, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVRbWwci3Fn4",
        "outputId": "34369fab-5478-4c0b-e015-d59b9d0a513f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2405892"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasta_path = \"/content/drive/MyDrive/SP/GCF_000001405.26_GRCh38_genomic.fna.gz\"\n",
        "L = 256           # velikost okna (context window)\n",
        "VOCAB_SIZE = 5    # A,C,G,T,MASK\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 10\n",
        "MASK_IDX = 4\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Wu6etD-SJczW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_random_seq(n=10000, L=256, alphabet='ACGT'):\n",
        "    for _ in range(n):\n",
        "        yield ''.join(random.choice(alphabet) for _ in range(L))"
      ],
      "metadata": {
        "id": "LXIYc1YTDH4a"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_fasta(filepath, max_length=10000):\n",
        "    seq = []\n",
        "    total_len = 0\n",
        "    with gzip.open(filepath, 'rt') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line.startswith('>'):\n",
        "                continue\n",
        "            to_take = max_length - total_len\n",
        "            if to_take <= 0:\n",
        "                break\n",
        "            seq.append(line[:to_take].upper())\n",
        "            total_len += len(line[:to_take])\n",
        "    return ''.join(seq)"
      ],
      "metadata": {
        "id": "sNWLuGunDKNy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sequences(mode='random', n=10000, L=256, fasta_path=None, max_len_fasta=None):\n",
        "    if mode == 'random':\n",
        "        return list(gen_random_seq(n, L))\n",
        "    elif mode == 'fasta':\n",
        "        assert fasta_path is not None, 'File path not found'\n",
        "        full_seq = read_fasta(fasta_path, max_length=max_len_fasta if max_len_fasta else L*n)\n",
        "        return [full_seq[i:i+L] for i in range(0, len(full_seq) - L + 1, L)]\n",
        "    else:\n",
        "        raise ValueError(\"mode must be 'random' or 'fasta'\")"
      ],
      "metadata": {
        "id": "5sH-HJjHDevS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seq_to_tokens(seq):\n",
        "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "    seq = seq.upper()\n",
        "    return [mapping.get(x, 0) for x in seq if x in mapping]"
      ],
      "metadata": {
        "id": "a_4zjLIjDlHs"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batches(sequences, L=256):\n",
        "    token_batches = []\n",
        "    for seq in sequences:\n",
        "        tokens = seq_to_tokens(seq)\n",
        "        if len(tokens) == L:\n",
        "            token_batches.append(tokens)\n",
        "    return token_batches"
      ],
      "metadata": {
        "id": "hqwRJzQp_Wxt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_input(x, mask_prob=0.15):\n",
        "    masked = x.clone()\n",
        "    mask = torch.rand_like(x.float()) < mask_prob\n",
        "    masked[mask] = 4\n",
        "    labels = x.clone()\n",
        "    labels[~mask] = -100\n",
        "    return masked, labels"
      ],
      "metadata": {
        "id": "gYpdLGBNIiDG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fasta_path = \"/content/drive/MyDrive/SP/GCF_000001405.26_GRCh38_genomic.fna.gz\"\n",
        "mode = \"random\"  # \"random\" / \"radnom\"\n",
        "n_samples = 100   # kolik sekvencí\n",
        "max_len_fasta = 10000   # kolik bází načíst z FASTA (ignoruje zbytek souboru)\n",
        "\n",
        "sequences = get_sequences(\n",
        "    mode=mode,\n",
        "    n=n_samples,\n",
        "    L=L,\n",
        "    fasta_path=fasta_path if mode == 'fasta' else None,\n",
        "    max_len_fasta=max_len_fasta if mode == 'fasta' else None\n",
        ")\n",
        "\n",
        "token_batches = prepare_batches(sequences, L)\n",
        "print(f\"Batchů připraveno: {len(token_batches)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNM1cPm1MhMG",
        "outputId": "f0606dc1-7df2-4340-dd18-c7acbfba79a3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batchů připraveno: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jFB-YXfwM1Va",
        "outputId": "689f6798-2d53-4e88-d560-0de94f5d276c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'TGCGGTGTGATTCAGGAGGGTGACGTTGGAAGTGGACAATGCATACGGGGCCTTCATGCCCTTTCCCAACTTGGCCTTATTGTAGAGGAATATTAACGCCGCCTCTGGTAGATAAGAGAGAAGGCGCCTTGGCCCGTAACACCTGTCGGTATCCCGTCAACGAATACGTGTCTTGTGCAGGTCATCCTTGCCTGAGTTATTTGGCCGCGATGTTACTAATGTGGTCCCCTGTCGTGCCGAGTGAACAACTCTGGTA'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token_batches[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CYP17QVrMxJA",
        "outputId": "bad26525-0b42-49d3-d95d-4d2fd07f4bc6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 0,\n",
              " 0,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 3,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 0,\n",
              " 2,\n",
              " 3,\n",
              " 2,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 3,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleDNATransformer(vocab_size=VOCAB_SIZE, max_len=L).to(DEVICE)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    indices = random.sample(range(len(token_batches)), min(BATCH_SIZE, len(token_batches)))\n",
        "    x = torch.tensor([token_batches[i] for i in indices], dtype=torch.long).to(DEVICE)\n",
        "    masked_x, labels = mask_input(x)\n",
        "    logits = model(masked_x)\n",
        "    loss = F.cross_entropy(\n",
        "        logits.view(-1, VOCAB_SIZE),\n",
        "        labels.view(-1),\n",
        "        ignore_index=-100\n",
        "    )\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    print(f\"Epoch {epoch} loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuInpGgTeyIA",
        "outputId": "eff2341c-ca80-40ca-accd-7e655ec5236e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 loss: 1.6671\n",
            "Epoch 1 loss: 1.7780\n",
            "Epoch 2 loss: 1.4508\n",
            "Epoch 3 loss: 1.5010\n",
            "Epoch 4 loss: 1.4568\n",
            "Epoch 5 loss: 1.4142\n",
            "Epoch 6 loss: 1.4049\n",
            "Epoch 7 loss: 1.4219\n",
            "Epoch 8 loss: 1.4250\n",
            "Epoch 9 loss: 1.4133\n"
          ]
        }
      ]
    }
  ]
}